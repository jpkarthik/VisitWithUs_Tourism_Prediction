name: Visit With Us Toursim Prediction Pipeline

on:
  push:
    branches:
      - main # Automatically triggers on push to the main branch
    paths:
      - 'Master/Data/tourism.csv'
      - 'Master/Model_Building/DataRegistration.py'
      - 'Master/Model_Building/DataPrepration.py'
      - 'Master/Model_Building/BuildingModels.py'
      - 'Master/Model_Building/main.py'
      - '.github/workflows/pipeline.yml'
  workflow_dispatch:

jobs:
  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
      
      - name: Setup python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy huggingface_hub python-dotenv datasets scikit-learn
      
      - name: Copy tourism.csv(if using a local file)
        run: |
          mkdir -p Master/Data cp tourism.csv Master/Data/ || echo "tourism.csv not found in root"
      
      - name: Run Data Registration
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd Master/Model_Building
          python main.py --job register
        continue-on-error: false

      - name: Check Pipeline status
        if: failure()
        run: |
          echo "Data Registration pipeline failed. please check logs"
          exit 1
      
      - name: Verify Upload
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Verifying Upload on Hugging Face"
          python -c "import os;from huggingface_hub import HfApi;api= HfApi(token=os.getenv('HF_TOKEN'));print(api.repo_info(repo_id='jpkarthikeyan/Tourism-visit-with-us-dataset',repo_type='dataset'))"

  data-prepration:
    runs-on: ubuntu-latest
    needs: register-dataset
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy huggingface_hub python-dotenv datasets scikit-learn

      - name: Copying tourism.csv
        run: |
          mkdir -p Master/Data
          cp tourism.csv Master/Data || echo "tourism.csv not found in root"

      - name: Run DataPrepration.py
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd Master/Model_Building
          python main.py --job prepare
        continue-on-error: false

      - name: Check Pipeline Status
        if: failure()
        run: |
          echo "Data Prepration pipeline failed. please check the log"
          exit 1
      - name: Verify Upload
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Verifying Upload on Hugging Face"
          python -c "import os; from huggingface_hub import HfApi; token = os.getenv('HF_TOKEN');print(HfApi(token=token).repo_info(repo_id='jpkarthikeyan/Tourism-visit-with-us-dataset', repo_type='dataset'))"

  model-building:
    runs-on: ubuntu-latest
    needs: data-prepration
    steps: 
      - name: Checkout Repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12' 
      
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install huggingface_hub python-dotenv pandas numpy scikit-learn joblib xgboost seaborn matplotlib datasets

      - name: Run Model Building
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd Master/Model_Building
          python main.py --job modelbuilding
        continue-on-error: false
      
      - name: Check pipeline status
        if: failure()
        run: |
          echo "Exception in Build Models. please check logs"
          exist 1
      
      - name: Verify Execution
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Verifying the execution"
          python -c "import os; from huggingface_hub import HfApi;token=os.getenv('HF_TOKEN');print(HfApi(token=token).repo_info(repo_id='jpkarthikeyan/Tourism_Prediction_Model',repo_type='model')) "

      - name: List Generated Files
        run: |
          ls -l Master/Model_Dump_JOBLIB/
      
      - name: Commit and Push Generated Files
        
        run: |
          git config --global user.name 'github-actions'
          git config --global user.email 'github-actions@users.noreply.github.com'
          git add Master/Model_Dump_JOBLIB/*
          git commit -m "Adding genearated model files and confusion matrix plots" || echo "No changes to commit"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}